{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7WQ46ZjkBC5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "META_PATH = \"/content/drive/MyDrive/UrbanSound8K.csv\"\n",
        "df = pd.read_csv(META_PATH)\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "print(df['class'].unique()[:20])   # í´ë˜ìŠ¤ëª… í™•ì¸\n",
        "print(df['classID'].unique()[:20]) # ìˆ«ì ID í™•ì¸"
      ],
      "metadata": {
        "id": "mQ4HDb1vELBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2name = {\n",
        "    0:'air_conditioner',\n",
        "    1:'car_horn',\n",
        "    2:'children_playing',\n",
        "    3:'dog_bark',\n",
        "    4:'drilling',\n",
        "    5:'engine_idling',\n",
        "    6:'gun_shot',\n",
        "    7:'jackhammer',\n",
        "    8:'siren',\n",
        "    9:'street_music'\n",
        "}"
      ],
      "metadata": {
        "id": "G19CHvvbEWHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['class'].unique())"
      ],
      "metadata": {
        "id": "ErswQd-xbqMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "\n",
        "BASE_DIR_US8K = \"/content/drive/MyDrive/fold2\"  # ë³¸ì¸ ê²½ë¡œ\n",
        "META_PATHS = [\n",
        "    os.path.join(BASE_DIR_US8K, \"metadata\", \"/content/drive/MyDrive/UrbanSound8K.csv\"),\n",
        "    os.path.join(BASE_DIR_US8K, \"/content/drive/MyDrive/UrbanSound8K.csv\"),\n",
        "]\n",
        "META_PATH = next((p for p in META_PATHS if os.path.exists(p)), None)\n",
        "assert META_PATH, \"UrbanSound8K.csv ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\"\n",
        "\n",
        "df = pd.read_csv(META_PATH)\n",
        "assert {'slice_file_name','fold','classID'}.issubset(df.columns), \"CSV ì»¬ëŸ¼ í™•ì¸ í•„ìš”\"\n",
        "\n",
        "sub = df[df['classID'].isin(target_ids)].copy()\n",
        "counts = sub.groupby(['fold','classID']).size().unstack(fill_value=0)\n",
        "print(\"foldë³„ car_horn(1)/siren(8) ë¶„í¬:\\n\", counts)"
      ],
      "metadata": {
        "id": "JTqzhQLEEg9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "\n",
        "BASE_DIR_US8K = \"/content/drive/MyDrive/fold2\"  # ë³¸ì¸ ê²½ë¡œ\n",
        "META_PATHS = [\n",
        "    os.path.join(BASE_DIR_US8K, \"metadata\", \"/content/drive/MyDrive/UrbanSound8K.csv\"),\n",
        "    os.path.join(BASE_DIR_US8K, \"/content/drive/MyDrive/UrbanSound8K.csv\"),\n",
        "]\n",
        "META_PATH = next((p for p in META_PATHS if os.path.exists(p)), None)\n",
        "assert META_PATH, \"UrbanSound8K.csv ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\""
      ],
      "metadata": {
        "id": "GWH8ikAsFzQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) ëŒ€ìƒ í´ë˜ìŠ¤/í´ë“œ\n",
        "TARGET_FOLD = 2\n",
        "ID2NAME = {0:'air_conditioner',1:'car_horn',2:'children_playing',3:'dog_bark',\n",
        "           4:'drilling',5:'engine_idling',6:'gun_shot',7:'jackhammer',\n",
        "           8:'siren',9:'street_music'}\n",
        "TARGET_IDS = [1, 8]  # car_horn, siren"
      ],
      "metadata": {
        "id": "Y1-Y-fQVH2TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) CSV ë¡œë“œ ë° ë¶„í¬ í™•ì¸\n",
        "df = pd.read_csv(META_PATH)\n",
        "need_cols = {'slice_file_name','fold','classID'}\n",
        "assert need_cols.issubset(df.columns), f\"CSV ì»¬ëŸ¼ ë¶€ì¡±: {df.columns}\"\n",
        "\n",
        "sub_all = df[df['classID'].isin(TARGET_IDS)]\n",
        "print(\"ì „ì²´ fold ë¶„í¬:\")\n",
        "print(sub_all.groupby(['fold','classID']).size().unstack(fill_value=0))\n",
        "\n",
        "sub = df[(df['fold']==TARGET_FOLD) & (df['classID'].isin(TARGET_IDS))].copy()\n",
        "print(f\"\\nfold{TARGET_FOLD} ë¶„í¬:\")\n",
        "print(sub['classID'].value_counts())  # ì—¬ê¸°ì„œ 1=car_horn, 8=siren (ì˜ˆìƒ: 1:42, 8:91)"
      ],
      "metadata": {
        "id": "VCVFjpaLH_iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) ê²½ë¡œ í•´ê²°(í´ë” êµ¬ì¡°/ëŒ€ì†Œë¬¸ì ìœ ì—° íƒìƒ‰)\n",
        "def resolve_path(base_dir, fold, fname):\n",
        "    patterns = [\n",
        "        Path(base_dir)/\"audio\"/f\"fold{fold}\"/fname,\n",
        "        Path(base_dir)/f\"fold{fold}\"/fname,\n",
        "        Path(base_dir)/\"audio\"/fname,\n",
        "        Path(base_dir)/fname,\n",
        "    ]\n",
        "    for p in patterns:\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "    # í™•ì¥ì ëŒ€ì†Œë¬¸ì ë³´ì •(.wav <-> .WAV)\n",
        "    if fname.lower().endswith(\".wav\"):\n",
        "        alt = fname[:-4] + \".WAV\"\n",
        "    else:\n",
        "        alt = fname + \".wav\"\n",
        "    for p in [\n",
        "        Path(base_dir)/\"audio\"/f\"fold{fold}\"/alt,\n",
        "        Path(base_dir)/f\"fold{fold}\"/alt,\n",
        "        Path(base_dir)/\"audio\"/alt,\n",
        "        Path(base_dir)/alt,\n",
        "    ]:\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "    return None\n",
        "\n",
        "pairs = []\n",
        "for _, r in sub.iterrows():\n",
        "    fpath = resolve_path(BASE, int(r['fold']), r['slice_file_name'])\n",
        "    if fpath:\n",
        "        pairs.append((fpath, ID2NAME[int(r['classID'])]))\n",
        "\n",
        "print(f\"\\n[US8K] fold{TARGET_FOLD}: {len(pairs)} files (car_horn/siren)\")\n",
        "print(\"ìƒ˜í”Œ:\", pairs[:5])\n"
      ],
      "metadata": {
        "id": "IoRgXs-2IC1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) ì „ì²˜ë¦¬: 1ì´ˆ ì°½ log-mel(64 mel) -> /content/dataset/fold2/X.npy, y.npy\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import math\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "SR=16000; N_MELS=64; WIN_LEN=1024; HOP_LEN=320\n",
        "SEG_SECONDS=1.0; SEG_SAMPLES=int(SR*SEG_SECONDS); SEG_HOP=int(SR*0.5)\n",
        "CLASS2IDX={'siren':0, 'car_horn':1}\n",
        "\n",
        "def load_mono(path, sr=SR):\n",
        "    y, orig = sf.read(path, always_2d=False)\n",
        "    if y.ndim>1: y = y.mean(axis=1)\n",
        "    if orig!=sr: y = librosa.resample(y=y, orig_sr=orig, target_sr=sr)\n",
        "    return y\n",
        "\n",
        "def segment(y, seg_len=SEG_SAMPLES, hop=SEG_HOP):\n",
        "    return [y[i:i+seg_len] for i in range(0, max(0, len(y)-seg_len+1), hop)]\n",
        "\n",
        "def to_logmel(y):\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=SR, n_fft=WIN_LEN, hop_length=HOP_LEN,\n",
        "                                       n_mels=N_MELS, power=2.0, fmin=20, fmax=SR//2)\n",
        "    return librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
        "\n",
        "def build_Xy(pairs):\n",
        "    X, y = [], []\n",
        "    T_target = math.ceil((SEG_SAMPLES - WIN_LEN) / HOP_LEN) + 1  # â‰ˆ49~50 í”„ë ˆì„\n",
        "    for fpath, cname in pairs:\n",
        "        wav = load_mono(fpath, SR)\n",
        "        for seg in segment(wav):\n",
        "            if len(seg) < SEG_SAMPLES: continue\n",
        "            mel = to_logmel(seg)  # (64, T)\n",
        "            if mel.shape[1] < T_target:\n",
        "                mel = np.pad(mel, ((0,0),(0,T_target-mel.shape[1])),\n",
        "                             mode='constant', constant_values=mel.min())\n",
        "            elif mel.shape[1] > T_target:\n",
        "                mel = mel[:, :T_target]\n",
        "            X.append(mel); y.append(CLASS2IDX[cname])\n",
        "    X = np.array(X, dtype=np.float32)[:,None,:,:]  # (N,1,64,T)\n",
        "    y = np.array(y, dtype=np.int64)\n",
        "    return X, y\n",
        "\n",
        "if len(pairs)==0:\n",
        "    print(\"âš ï¸ fold2ì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. BASE/í´ë” êµ¬ì¡°/íŒŒì¼ëª… ëŒ€ì†Œë¬¸ìë¥¼ ì¬í™•ì¸í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    X, y = build_Xy(pairs)\n",
        "    outdir = \"/content/dataset/fold2\"; os.makedirs(outdir, exist_ok=True)\n",
        "    np.save(f\"{outdir}/X.npy\", X); np.save(f\"{outdir}/y.npy\", y)\n",
        "    with open(f\"{outdir}/label_map.txt\",\"w\") as f:\n",
        "        f.write(\"0\\tsiren\\n1\\tcar_horn\\n\")\n",
        "    print(f\"âœ… Saved: {outdir} | X{X.shape}, y{y.shape}\")"
      ],
      "metadata": {
        "id": "miOSh3kaIE34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) ë°ì´í„° ë¡œë“œ & í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬"
      ],
      "metadata": {
        "id": "RAxDdKMqnCPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.load(\"/content/dataset/fold2/X.npy\")  # (N,1,64,T)\n",
        "y = np.load(\"/content/dataset/fold2/y.npy\")  # (N,)\n",
        "# Keras ì…ë ¥ í˜•ìƒ: (N, 64, T, 1)\n",
        "X = np.transpose(X, (0,2,3,1))  # (N,64,T,1)\n",
        "\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_tr.shape, X_va.shape, y_tr.shape, y_va.shape"
      ],
      "metadata": {
        "id": "I4b57lHlm5wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) ê²½ëŸ‰ CNN ëª¨ë¸ ì •ì˜ & í•™ìŠµ"
      ],
      "metadata": {
        "id": "fOFWX8ZanJ-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "inputs = keras.Input(shape=X_tr.shape[1:])  # (64, T, 1)\n",
        "x = layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool2D((2,2))(x)\n",
        "\n",
        "x = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPool2D((2,2))(x)\n",
        "\n",
        "x = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "cb = [\n",
        "  keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
        "  keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.5)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_tr, y_tr,\n",
        "    validation_data=(X_va, y_va),\n",
        "    epochs=30, batch_size=64,\n",
        "    callbacks=cb, verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "l67XHSh6nJWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_va), axis=1)\n",
        "print(confusion_matrix(y_va, y_pred))\n",
        "print(classification_report(y_va, y_pred, target_names=[\"siren\",\"car_horn\"]))"
      ],
      "metadata": {
        "id": "LOOSUOvum6mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# y_va: ì‹¤ì œ ë ˆì´ë¸”\n",
        "# y_pred: ì˜ˆì¸¡ëœ ë ˆì´ë¸”\n",
        "labels = [\"siren\", \"car_horn\"]\n",
        "\n",
        "# í˜¼ë™í–‰ë ¬ ìƒì„±\n",
        "cm = confusion_matrix(y_va, y_pred)\n",
        "\n",
        "# pandas DataFrameìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ë³€í™˜\n",
        "cm_df = pd.DataFrame(cm, index=[f\"True_{l}\" for l in labels],\n",
        "                         columns=[f\"Pred_{l}\" for l in labels])\n",
        "\n",
        "print(\"ğŸ“Š Confusion Matrix:\")\n",
        "print(cm_df)\n",
        "\n",
        "# ë¶„ë¥˜ ë¦¬í¬íŠ¸ë„ í•¨ê»˜ ì¶œë ¥\n",
        "print(\"\\nğŸ“‹ Classification Report:\")\n",
        "print(classification_report(y_va, y_pred, target_names=labels))"
      ],
      "metadata": {
        "id": "jmBVvNk5pWUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"siren\", \"car_horn\"], yticklabels=[\"siren\", \"car-horn\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(' Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1e1bzaupqed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SavedModel\n",
        "model.export(\"/content/safesound_cnn\")\n",
        "\n",
        "# TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/safesound_cnn\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # ê²½ëŸ‰í™”\n",
        "tflite_model = converter.convert()\n",
        "with open(\"/content/safesound_cnn.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "print(\"âœ… Exported /content/safesound_cnn.tflite\")"
      ],
      "metadata": {
        "id": "VaNuxAAwqZFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa, soundfile as sf, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "SR=16000; N_MELS=64; WIN_LEN=1024; HOP_LEN=320\n",
        "SEG_SECONDS=1.0; SEG_SAMPLES=int(SR*SEG_SECONDS); SEG_HOP=int(SR*0.5)\n",
        "ENTER_TH=0.8; EXIT_TH=0.6; MIN_CONSEC=2  # 1ì´ˆ ì°½ì—ì„œ 2ì—°ì†=ì•½ 1ì´ˆ ì§€ì†\n",
        "\n",
        "interpreter = tf.lite.Interpreter(\"/content/safesound_cnn.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "in_detail = interpreter.get_input_details()[0]\n",
        "out_detail = interpreter.get_output_details()[0]\n",
        "\n",
        "def logmel_1s(y):\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=SR, n_fft=WIN_LEN, hop_length=HOP_LEN,\n",
        "                                       n_mels=N_MELS, power=2.0, fmin=20, fmax=SR//2)\n",
        "    S = librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
        "    # ê¸¸ì´ ë³´ì •(Tâ‰ˆ49~50)\n",
        "    T_target = math.ceil((SEG_SAMPLES - WIN_LEN)/HOP_LEN)+1\n",
        "    if S.shape[1] < T_target:\n",
        "        S = np.pad(S, ((0,0),(0,T_target-S.shape[1])), mode=\"constant\", constant_values=S.min())\n",
        "    elif S.shape[1] > T_target:\n",
        "        S = S[:, :T_target]\n",
        "    return S  # (64,T)\n",
        "\n",
        "def sliding_segments(y):\n",
        "    segs = []\n",
        "    for st in range(0, max(0, len(y)-SEG_SAMPLES+1), SEG_HOP):\n",
        "        segs.append(y[st:st+SEG_SAMPLES])\n",
        "    return segs\n",
        "\n",
        "def predict_file(path):\n",
        "    y, sr = sf.read(path, always_2d=False)\n",
        "    if y.ndim>1: y=y.mean(axis=1)\n",
        "    if sr!=SR:  y=librosa.resample(y, orig_sr=sr, target_sr=SR, res_type='kaiser_fast')\n",
        "\n",
        "    probs=[]\n",
        "    for seg in sliding_segments(y):\n",
        "        if len(seg)<SEG_SAMPLES: continue\n",
        "        mel = logmel_1s(seg)                # (64,T)\n",
        "        mel = mel[np.newaxis,...,np.newaxis]# (1,64,T,1)\n",
        "        interpreter.set_tensor(in_detail['index'], mel)\n",
        "        interpreter.invoke()\n",
        "        p = interpreter.get_tensor(out_detail['index'])[0]  # (2,)\n",
        "        probs.append(p)  # [p_siren, p_car_horn]\n",
        "    probs = np.array(probs)\n",
        "    return probs  # (N,2)\n",
        "\n",
        "def smooth_and_decide(probs, cls=0):\n",
        "    # cls=0: siren, 1: car_horn\n",
        "    cnt=0; events=[]\n",
        "    active=False\n",
        "    for i,p in enumerate(probs[:,cls]):\n",
        "        if not active:\n",
        "            if p>=ENTER_TH:\n",
        "                cnt+=1\n",
        "                if cnt>=MIN_CONSEC:\n",
        "                    active=True\n",
        "                    start=i-MIN_CONSEC+1\n",
        "                    cnt=0\n",
        "            else:\n",
        "                cnt=0\n",
        "        else:\n",
        "            if p<=EXIT_TH:\n",
        "                active=False\n",
        "                events.append((start, i))  # [start_idx, end_idx]\n",
        "    if active:\n",
        "        events.append((start, len(probs)-1))\n",
        "    return events\n",
        "\n",
        "# ì‹¤í–‰ ì˜ˆì‹œ\n",
        "probs = predict_file(\"/content/example.wav\")  # ì˜ˆì‹œ íŒŒì¼ ê²½ë¡œ\n",
        "siren_events = smooth_and_decide(probs, cls=0)\n",
        "horn_events  = smooth_and_decide(probs, cls=1)\n",
        "print(\"SIREN events:\", siren_events)\n",
        "print(\"CAR_HORN events:\", horn_events)\n"
      ],
      "metadata": {
        "id": "qGP0dAfExcYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ioQm2wnFx-TH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}